#!/usr/bin/env python
# coding: utf-8

# In[1]:


my_dict = { 'name' : ["a", "b", "c", "d", "e","f", "g"],
                   'age' : [20,27, 35, 55, 18, 21, 35],
                   'designation': ["VP", "CEO", "CFO", "VP", "VP", "CEO", "MD"]}

import pandas as pd
import numpy as np
df = pd.DataFrame(my_dict)
df


# In[2]:


df.to_csv('csv_example')
df


# In[3]:


df_csv = pd.read_csv('csv_example')
df_csv


# In[4]:


df.to_csv('csv_example', index=False)
df_csv = pd.read_csv('csv_example')
df_csv


# In[18]:


import pandas as pd
Location = '/Users/girishmeghanani/FDS_Practicals' + '/student-mat.csv'
df = pd.read_csv(Location, header=None)
df.head()


# In[19]:


import pandas as pd
Location = '/Users/girishmeghanani/FDS_Practicals' + '/student-mat.csv'
df = pd.read_csv(Location)
df.head()


# In[20]:


import pandas as pd
Location =  '/Users/girishmeghanani/FDS_Practicals' + '/student-mat.csv'
# To add headers as we load the data...
df = pd.read_csv(Location, names=['RollNo','Names','Grades'])
# To add headers to a dataframe
df.columns = ['RollNo','Names','Grades']
df.head()


# In[21]:


import pandas as pd
names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,95,77,78,99]
bsdegrees = [1,1,0,0,1]
msdegrees = [2,1,0,0,0]
phddegrees = [0,1,0,0,0]
Degrees = zip(names,grades,bsdegrees,msdegrees,phddegrees)
columns = ['Names','Grades','BS','MS','PhD']
df = pd.DataFrame(data = Degrees, columns=columns)
df


# In[23]:


import pandas as pd
Location = '/Users/girishmeghanani/FDS_Practicals' + '/gradedata.xlsx'
df = pd.read_excel(Location)

#Changing column Names
df.columns = ['first','last','sex','age','exer','hrs','grd','addr']
df.head()


# In[24]:


import pandas as pd
names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,95,77,78,99]
GradeList = zip(names,grades)
df = pd.DataFrame(data = GradeList,columns=['Names','Grades'])
writer = pd.ExcelWriter('dataframe.xlsx', engine='xlsxwriter')
df.to_excel(writer, sheet_name='Sheet1')
writer.save()

#It turns out that pandas cannot read Excel files on its own, so we need to install another python package to do that.
#To install  excel writer execute following command
#### pip install xlsxwriter


#There are 2 options that we have: xlrd and openpyxl. The package xlrd can open both Excel 2003 (.xls) and Excel 2007+ (.xlsx) files, whereas openpyxl can open only Excel 2007+ (.xlsx) files. So, we will install xlrd as it can open both formats:

##########   pip install xlrd
##########  pip install xlwt openpyxl


# In[4]:


import sqlite3

# Create a SQL connection to our SQLite database
con = sqlite3.connect('/Users/girishmeghanani/FDS_Practicals' + 'portal_mammals.sqlite')

cur = con.cursor()

# The result of a "cursor.execute" can be iterated over by row
for row in cur.execute("SELECT * FROM species;"):
    print(row)

# Be sure to close the connection
con.close()


# In[3]:


import sqlite3

# Create a SQL connection to our SQLite database
con = sqlite3.connect('/Users/girishmeghanani/FDS_Practicals' + 'portal_mammals.sqlite')

cur = con.cursor()

# Return all results of query
cur.execute('SELECT plot_id FROM plots WHERE plot_type="Control"')
print(cur.fetchall())

# Return first result of query
cur.execute('SELECT species FROM species WHERE taxa="Bird"')
print(cur.fetchone())

# Be sure to close the connection
con.close()


# In[6]:


import pandas as pd
import sqlite3

# Read sqlite query results into a pandas DataFrame
con = sqlite3.connect('/Users/girishmeghanani/FDS_Practicals' + 'portal_mammals.sqlite')
df = pd.read_sql_query("SELECT * from surveys", con)

# Verify that result of SQL query is stored in the dataframe
print(df.head())

con.close()


# In[7]:


from pandas import DataFrame
Cars={'Brand':['Honda Civic','Toyota Corolla','Ford Focus','Audi A4'],
      'Price':[22000,25000,27000,35000]
      }
df=DataFrame(Cars,columns=['Brand','Price'])
print(df)


# In[8]:


import sqlite3


# In[9]:


conn=sqlite3.connect('TestDB1.db')
c=conn.cursor()


# In[10]:


c.execute('CREATE TABLE CARS1(Brand text, Price number)')
conn.commit()


# In[11]:


df.to_sql('CARS',conn,if_exists='replace',index=False)
df


# In[12]:


c.execute('''
SELECT Brand,max(Price) from CARS
''')


# In[13]:


df=DataFrame(c.fetchall(),columns=['Brand','Price'])
df


# # Example 1

# In[14]:


import pandas as pd 
import os
import sqlite3 as lite
from sqlalchemy import create_engine

studentId=["rj101","rj150","rj134","rj70"]
SName=["Saurabh","Giftson","Vikas","Radha"]
LName=["Chavan","Paul","Bisoi","Rai"]
Department=["Bms","Bcom","BscCS","BScIT"]
Email=["100rabh@gmail.com","gift01@gmail.com","vik21@gmail.com","rad01@gmail.com"]

studata = zip(studentId,SName,LName,Department,Email)
df = pd.DataFrame(data =studata, columns=['StudentId','SName','LName','Department','Email'])
df.to_csv('studentdata.csv',index=False,header=False)

df
df1=df.to_csv('studentdata.csv',index=False,header=True)
 
df2=df.to_excel('studentdata2.xlsx',index=False,header=True)
 
db_filename = r'studentdata.db'
con = lite.connect(db_filename)
df.to_sql('student',
con,
schema=None,
if_exists='replace',
index=True,
index_label=None,
chunksize=None,
dtype=None)
con.close()

dfcsv=pd.read_csv("studentdata.csv")
dfcsv


dfex=pd.read_excel("studentdata2.xlsx")
dfex

db_file = r'studentdata.db'
engine = create_engine(r"sqlite:///{}" .format(db_file))
sql = 'SELECT * from student '


studf = pd.read_sql(sql, engine)
studf


# # Example 2

# In[15]:


import pandas as pd
import os
import sqlite3 as lite
from sqlalchemy import create_engine
 
EmpId=["E101","E102","E103","E104"]
FName=["Shweta","Manisha","Madhu","Anita"]
LName=["Subnis","Perdesi","Mali","Rai"]
Designation=["ProjectEngineer","Tester","SrSoftwareEngineer","WebDeveloper"]
Basic_Salary=[40000,50000,60000,70000]
 
Empdata = zip(EmpId,FName,LName,Designation,Basic_Salary)
df = pd.DataFrame(data =Empdata, columns=['EmpId','FName','LName','Designation','Basic_Salary'])
df.to_csv('studentgrades.csv',index=False,header=False)
 
 
 
df
 
df1=df.to_csv('employeedata.csv',index=False,header=True)
 
df2=df.to_excel('employeedata2.xlsx',index=False,header=True)
 
db_filename = r'employee.db'
con = lite.connect(db_filename)
df.to_sql('employee',
con,
schema=None,
if_exists='replace',
index=True,
index_label=None,
chunksize=None,
dtype=None)
con.close()
 
dfcsv=pd.read_csv("employeedata.csv")
 
dfcsv
 
dfex=pd.read_excel("employeedata2.xlsx")
dfex
 
db_file = r'employee.db'
engine = create_engine(r"sqlite:///{}" .format(db_file))
sql = 'SELECT * from employee '
'where Basic_Salary in (40000,50000,60000,70000)'
empdf = pd.read_sql(sql, engine)
empdf


# # Example 3

# In[16]:


import pandas as pd 
import os
import sqlite3 as lite
from sqlalchemy import create_engine

sales_Representative=["sara","farahan","patrick","francheska","Henry","preson"]
Location=["New_York","Oregon","New_Jersy","New_York","Washington","Oregon"]
Region=["East","west","East","East","West","East"]
Customer=["Justin","Roy","Aian","Franklin","Danie","Phyllis"]
Item=["Watch","Mobile","Stationary","Jeans","Mobile","TV"]
Quantity=[2,1,15,2,1]
Price=[1000,25000,500,5750,10000,50000]

saledata = zip(sales_Representative,Location,Region,Customer,Item,Quantity,Price)
df = pd.DataFrame(data =saledata, columns=['sales_Representative','Location','Region','Customer','Item','Quantity','Price'])
df.to_csv('salestdata.csv',index=False,header=False)


df
df1=df.to_csv('sale1tdata.csv',index=False,header=True)
 
df2=df.to_excel('sale2.xlsx',index=False,header=True)
 
db_filename = r'salesmandata.db'
con = lite.connect(db_filename)
df.to_sql('salesman',
con,
schema=None,
if_exists='replace',
index=False,
index_label=None,
chunksize=None,
dtype=None)
con.close()

dfcsv=pd.read_csv("sale1tdata.csv")
dfcsv


dfex=pd.read_excel("sale2.xlsx")
dfex

db_file = r'salesmandata.db'
engine = create_engine(r"sqlite:///{}" .format(db_file))
sql = 'SELECT * from salesman '


saledf = pd.read_sql(sql, engine)
saledf


# # Example 4

# In[18]:


import pandas as pd 
import os
import sqlite3 as lite
from sqlalchemy import create_engine
  
# list of name, degree, score 
nme = ["aparna", "pankaj", "sudhir", "Geeku"] 
deg = ["MBA", "BCA", "M.Tech", "MBA"] 
scr = [90, 40, 80, 98] 
  
# dictionary of lists  
dict = {'name': nme, 'degree': deg, 'score': scr}  
    
df = pd.DataFrame(dict) 
    
df  
df.to_csv('scoredata.csv',index=False,header=False)


df
df1=df.to_csv('scoredata1.csv',index=False,header=True)
 
df2=df.to_excel('scoredata2.xlsx',index=False,header=True)
 
db_filename = r'score.db'
con = lite.connect(db_filename)
df.to_sql('scoretable',
con,
schema=None,
if_exists='replace',
index=False,
index_label=None,
chunksize=None,
dtype=None)
con.close()

dfcsv=pd.read_csv("scoredata1.csv")
dfcsv


dfex=pd.read_excel("scoredata2.xlsx")
dfex

db_file = r'score.db'
engine = create_engine(r"sqlite:///{}" .format(db_file))
sql = 'SELECT * from scoretable where score is 90'


scoredf = pd.read_sql(sql, engine)
scoredf


# # Example 5

# In[19]:


import pandas as pd 
import os
import sqlite3 as lite
from sqlalchemy import create_engine

# Create two lists in Python
education = ["Bachelor's", "Less than Bachelor's",
             "Master's","PhD","Professional"]
salary = [110000,105000,126000,144200,96000]

# create a dictionary using lists
a_dict = {"Education":education,
                  "Salary":salary}

# Create a data frame using the dictionary
df = pd.DataFrame(a_dict)
df

df.to_csv('salarydata.csv',index=False,header=False)


df
df1=df.to_csv('salarydata1.csv',index=False,header=True)
 
df2=df.to_excel('salarydata2.xlsx',index=False,header=True)
 
db_filename = r'salary.db'
con = lite.connect(db_filename)
df.to_sql('salarytable',
con,
schema=None,
if_exists='replace',
index=False,
index_label=None,
chunksize=None,
dtype=None)
con.close()

dfcsv=pd.read_csv("salarydata1.csv")
dfcsv


dfex=pd.read_excel("salarydata2.xlsx")
dfex

db_file = r'salary.db'
engine = create_engine(r"sqlite:///{}" .format(db_file))
sql = 'SELECT * from salarytable where salary is 144200'


scoredf = pd.read_sql(sql, engine)
scoredf


# # example 1

# In[20]:


import numpy as np
import pandas as pd


# In[21]:


state=pd.read_csv('/Users/girishmeghanani/FDS_Practicals' + '/US_violent_crime.csv')
state.head()


# In[22]:


#apply
def some_func(x):
  return x*2
state.apply(some_func) #update each entry of dataframe without any loop
state.apply(lambda n: n*2) #lambda also works the same


# In[23]:


#transform
state.transform(func = lambda x : x * 10)


# In[24]:


#usinggroupby
mean_purchase =state.groupby('State')["Murder"].mean().rename("User_mean").reset_index() 
print(mean_purchase)


# In[25]:


mer=state.merge(mean_purchase)
mer


# In[26]:


#checking for missing values
print(state.isnull().sum())


# # example 2

# In[27]:


import pandas as pd
import numpy as np
cols=['col0', 'col1', 'col2', 'col3', 'col4']
rows=['row0', 'row1', 'row2', 'row3', 'row4']
data=np.random.randint(0, 100, size=(5,5))
df=pd.DataFrame(data, columns=cols, index=rows)
df.head()


# In[28]:


df.iloc[4, 2]


# In[29]:


df.iloc[3, 3]=0
df.iloc[1, 2]=np.nan
df.iloc[4, 0]=np.nan
df['col5']=0
df['col6']=np.nan
df.head()


# In[30]:


#use all() method to select columns that don't have zero values
df.loc[:, df.all()]


# In[31]:


#display column that have atleast one non zero value
df.loc[:, df.any()]


# In[32]:


#select columns with any nan
df.loc[:,df.isnull().any()]


# In[33]:


#select column withou nan
df.loc[:, df.notnull().all()]


# In[34]:


df.dropna(how="all", axis=1) #if all the values in columns are nan it will be dropped


# In[35]:


#filling mean value at the place of nan value
df.fillna(df.mean())


# In[36]:


def some_func(x):
  return x*2
df.apply(some_func) #update each entry of dataframe without any loop
df.apply(lambda n: n*2) #lambda also works the same


# In[37]:


#these function do not return the transformation so we have to store it explicitly
df['new_col']=df['col4'].apply(lambda n: n*2)
df.head()


# In[38]:


#Transforming function in Python
import pandas as pd
import numpy as np
#creating a dataframe
df=pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])
df


# In[39]:


#applying the transform function
df.transform(func = lambda x : x * 10)


# In[40]:


#Demonstrate transfomr function using pandas in python
import pandas as pd
import numpy as np
import random
data = pd.DataFrame({
    'C' : [random.choice(('a','b','c')) for i in range(1000000)],
    'A' : [random.randint(1,10) for i in range(1000000)],
    'B' : [random.randint(1,10) for i in range(1000000)]

})
data


# In[41]:


#use the merge procedure
data.groupby('C')["A"].mean()
mean =data.groupby('C')["A"].mean().rename("N").reset_index()
df_1 = data.merge(mean)


# In[42]:


data['N3'] = data.groupby(['C'])['A'].transform('mean')


# In[43]:


#with apply() function

df['d'] = df.apply(lambda row: row.a + row.b + row.c, axis=1)


# # example 3

# In[45]:


import pandas as pd
import numpy as np
Airline=pd.read_csv('/Users/girishmeghanani/FDS_Practicals' + '/airline_stats.csv')
Airline.head()


# In[46]:


#cheaking missing values
print(Airline.isnull().sum())


# In[47]:


Airline.fillna(Airline.mean(), inplace=True)
Airline.isnull().sum()


# # Groupby

# In[48]:


mean_purchase =Airline.groupby('pct_atc_delay')["pct_weather_delay"].mean().rename("User").reset_index() 
print(mean_purchase)


# In[49]:


mean_purchase =Airline.groupby('pct_atc_delay')["pct_weather_delay"].mean().rename("User").reset_index() 
print(mean_purchase)
df = Airline.merge(mean_purchase)
df


# In[50]:


#applying the transform function
Airline.transform( lambda x : x * 10 )


# In[51]:


#applying the apply function
Airline.apply(lambda n: n *2,axis=1)


# In[ ]:




